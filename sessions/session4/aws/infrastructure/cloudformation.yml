AWSTemplateFormatVersion: '2010-09-09'
Description: 'Retail Data Pipeline - Session 4 AWS Infrastructure (dbt runs locally, Lambda via EventBridge)'

Parameters:
  ProjectName:
    Type: String
    Default: retail-pipeline-session4
    Description: Project name prefix for resources

  Environment:
    Type: String
    Default: dev
    AllowedValues: [dev, prod]
    Description: Environment name

  DBPassword:
    Type: String
    NoEcho: true
    MinLength: 8
    Description: RDS PostgreSQL master password

  DataBucketName:
    Type: String
    Description: S3 bucket name for data (must be globally unique)
    Default: retail-pipeline-data-session4-YOUR_UNIQUE_ID

  AllowedCIDR:
    Type: String
    Description: CIDR block allowed to access RDS (your IP for local dbt connection)
    Default: 0.0.0.0/0

Resources:
  # ==================== VPC & Networking ====================
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-vpc'
        - Key: Project
          Value: !Ref ProjectName

  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Project
          Value: !Ref ProjectName

  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref InternetGateway

  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select [0, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-public-1'

  PublicSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: !Select [1, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-public-2'

  PrivateSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.11.0/24
      AvailabilityZone: !Select [0, !GetAZs '']
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-private-1'

  PrivateSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.12.0/24
      AvailabilityZone: !Select [1, !GetAZs '']
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-private-2'

  NatGatewayEIP:
    Type: AWS::EC2::EIP
    DependsOn: AttachGateway
    Properties:
      Domain: vpc

  NatGateway:
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NatGatewayEIP.AllocationId
      SubnetId: !Ref PublicSubnet1
      Tags:
        - Key: Project
          Value: !Ref ProjectName

  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-public-rt'

  PublicRoute:
    Type: AWS::EC2::Route
    DependsOn: AttachGateway
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet1
      RouteTableId: !Ref PublicRouteTable

  PublicSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet2
      RouteTableId: !Ref PublicRouteTable

  PrivateRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-private-rt'

  PrivateRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway

  PrivateSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet1
      RouteTableId: !Ref PrivateRouteTable

  PrivateSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet2
      RouteTableId: !Ref PrivateRouteTable

  # ==================== S3 Bucket ====================
  DataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref DataBucketName
      NotificationConfiguration:
        EventBridgeConfiguration:
          EventBridgeEnabled: true
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldData
            Status: Enabled
            ExpirationInDays: 90
            NoncurrentVersionExpirationInDays: 30
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      Tags:
        - Key: Project
          Value: !Ref ProjectName
        - Key: Environment
          Value: !Ref Environment

  # ==================== RDS PostgreSQL ====================
  DBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: Subnet group for RDS
      SubnetIds:
        - !Ref PublicSubnet1
        - !Ref PublicSubnet2
      Tags:
        - Key: Project
          Value: !Ref ProjectName

  DBSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for RDS PostgreSQL
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432
          CidrIp: !Ref AllowedCIDR
      Tags:
        - Key: Project
          Value: !Ref ProjectName

  RDSInstance:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: !Sub '${ProjectName}-${Environment}'
      DBName: retail_db
      Engine: postgres
      MultiAZ: false
      EngineVersion: '17.2'
      DBInstanceClass: db.t3.micro
      AllocatedStorage: 20
      StorageType: gp2
      MasterUsername: postgres
      MasterUserPassword: !Ref DBPassword
      DBSubnetGroupName: !Ref DBSubnetGroup
      VPCSecurityGroups:
        - !Ref DBSecurityGroup
      PubliclyAccessible: true
      BackupRetentionPeriod: 0
      PreferredBackupWindow: '03:00-04:00'
      PreferredMaintenanceWindow: 'sun:04:00-sun:05:00'
      EnableCloudwatchLogsExports:
        - postgresql
      DeletionProtection: false
      Tags:
        - Key: Project
          Value: !Ref ProjectName
        - Key: Environment
          Value: !Ref Environment

  # ==================== SNS Topic ====================
  PipelineTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub '${ProjectName}-notifications'
      DisplayName: Retail Pipeline Notifications
      Tags:
        - Key: Project
          Value: !Ref ProjectName

  # ==================== Lambda ====================
  LambdaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Lambda SG
      VpcId: !Ref VPC
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Project
          Value: !Ref ProjectName

  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${ProjectName}-lambda-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: LambdaS3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:GetObjectMetadata
                Resource: !Sub '${DataBucket.Arn}/*'
        - PolicyName: LambdaCloudWatchLogs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'
        - PolicyName: LambdaRDSAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - rds:DescribeDBInstances
                Resource: '*'
        - PolicyName: LambdaSNSPublish
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - sns:Publish
                Resource: !Ref PipelineTopic

  S3EventHandlerFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-s3-event-handler'
      Runtime: python3.11
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          from datetime import datetime

          sns = boto3.client('sns')
          s3 = boto3.client('s3')

          def lambda_handler(event, context):
              print(f"Event received: {json.dumps(event)}")
              
              # 1. Handle S3 Event via EventBridge (No 'Records' key)
              if event.get('source') == 'aws.s3' and event.get('detail-type') == 'Object Created':
                  detail = event['detail']
                  bucket = detail['bucket']['name']
                  key = detail['object']['key']
                  size = detail['object']['size']
                  
                  print(f"EventBridge S3 detected: s3://{bucket}/{key} ({size} bytes)")
                  
                  # Prepare the message for SNS
                  message = {
                      "event": "s3_upload_via_eventbridge",
                      "bucket": bucket,
                      "key": key,
                      "size": size,
                      "timestamp": datetime.now().isoformat(),
                      "action_required": "Run local dbt to process data",
                      "command": f"cd session4/local && dbt run --target aws"
                  }
                  
                  send_sns_notification(message, key)
                  return {'statusCode': 200, 'body': json.dumps(message)}

              # 2. Handle Standard S3 Notification (Legacy/Direct Trigger)
              elif 'Records' in event:
                  # (Keep your existing 'Records' logic here if you still want to support it)
                  print("Standard S3 'Records' event detected")
                  # ... your existing logic ...
                  return {'statusCode': 200, 'body': 'Processed standard S3 event'}

              # 3. Handle Scheduled Cron
              else:
                  print("Scheduled cron event or unknown trigger received")
                  return {'statusCode': 200, 'body': json.dumps({'message': 'Scheduled Lambda executed'})}

          def send_sns_notification(message, key):
              topic_arn = os.environ.get('TOPIC_ARN')
              if topic_arn:
                  sns.publish(
                      TopicArn=topic_arn,
                      Subject=f'Data Pipeline: New file uploaded - {key}',
                      Message=json.dumps(message, indent=2)
                  )
                  print(f"SNS notification sent to {topic_arn}")

      Environment:
        Variables:
          DB_HOST: !GetAtt RDSInstance.Endpoint.Address
          DB_PORT: '5432'
          DB_NAME: retail_db
          S3_BUCKET: !Ref DataBucket
          TOPIC_ARN: !Ref PipelineTopic
      MemorySize: 256
      Timeout: 60
      VpcConfig:
        SecurityGroupIds:
          - !Ref LambdaSecurityGroup
        SubnetIds:
          - !Ref PrivateSubnet1
          - !Ref PrivateSubnet2
      Tags:
        - Key: Project
          Value: !Ref ProjectName

  LambdaEventBridgePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref S3EventHandlerFunction
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com

  ScheduledEventRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub '${ProjectName}-schedule'
      ScheduleExpression: 'rate(5 minutes)' 
      State: ENABLED
      Targets:
        - Arn: !GetAtt S3EventHandlerFunction.Arn
          Id: LambdaCronTarget

  S3EventBridgeRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub '${ProjectName}-s3-events'
      Description: Trigger Lambda when new objects uploaded to S3
      EventPattern:
        source:
          - aws.s3
        detail-type:
          - Object Created
        resources:
          - !GetAtt DataBucket.Arn
      State: ENABLED
      Targets:
        - Arn: !GetAtt S3EventHandlerFunction.Arn
          Id: LambdaS3Target

Outputs:
  DataBucketName:
    Description: S3 bucket for data files
    Value: !Ref DataBucket
    Export:
      Name: !Sub '${AWS::StackName}-DataBucket'

  RDSEndpoint:
    Description: RDS PostgreSQL endpoint for dbt connection
    Value: !GetAtt RDSInstance.Endpoint.Address
    Export:
      Name: !Sub '${AWS::StackName}-RDSEndpoint'

  RDSPort:
    Description: RDS PostgreSQL port
    Value: !GetAtt RDSInstance.Endpoint.Port
    Export:
      Name: !Sub '${AWS::StackName}-RDSPort'

  DatabaseName:
    Description: Database name
    Value: retail_db

  LambdaFunctionArn:
    Description: S3/EventBridge Lambda ARN
    Value: !GetAtt S3EventHandlerFunction.Arn

  SNSTopicArn:
    Description: SNS Topic for pipeline notifications
    Value: !Ref PipelineTopic

  VPCId:
    Description: VPC ID
    Value: !Ref VPC
    Export:
      Name: !Sub '${AWS::StackName}-VPC'

  ConnectionCommand:
    Description: Command to connect to RDS from local machine
    Value: !Sub 'psql -h ${RDSInstance.Endpoint.Address} -p 5432 -U postgres -d retail_db'

  dbtProfileConfig:
    Description: Add this to your dbt profiles.yml
    Value: !Sub |
      host: ${RDSInstance.Endpoint.Address}
      port: 5432
      user: postgres
      password: ${DBPassword}
      dbname: retail_db
      schema: public_silver